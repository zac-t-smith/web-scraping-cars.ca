import requests
import pandas as pd
from bs4 import BeautifulSoup
import os

cwd = os.getcwd()

url = requests.get('https://www.carpages.ca/used-cars/search/?category_id=1')
baseUrl = 'https://www.carpages.ca'
soup= BeautifulSoup(url.text,'lxml')
df = pd.DataFrame({'name':[],'price':[],'color':[],'link':[]})

while True:
    details = soup.find_all('div',class_='media__content')
    for data in details:
        name = data.h4.find('a').text
        price= data.find('strong').text.strip()
        link = data.h4.find('a')['href']
        link = baseUrl+link
        df=df.append({'name':name,'price':price,'link':link},ignore_index=True)
        try:
            color= data.find_all('div')[6].span.text.strip()
            df=df.append({'color':color})
        except:
            pass

    next_page_find = soup.find('a',{'title':'Next Page'})["href"]
    next_page_full = requests.get(baseUrl+next_page_find)
    url = next_page_full
    soup = BeautifulSoup(url.text,'lxml')
    
    df.to_csv(cwd+'\cars.csv',index=False)
    if next_page_find[50:] =='10':
        break
